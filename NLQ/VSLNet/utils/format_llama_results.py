import argparse
import json
import os
import random
import uuid
    
def format_llama_results_for_vslnet(llama_results, output_dir, split_ratios=(0.7, 0.15, 0.15)):
    """
    Format LLaMA-generated results for VSLNet pretraining and fine-tuning.
    
    Args:
    - llama_results (dict): Dictionary with LLaMA-generated results.
    - output_dir (str): Directory to save formatted JSON files.
    - split_ratios (tuple): Ratios for splitting data into train, val, and test sets.
    
    Returns:
    - None
    """
    # Split data into train, val, and test sets
    video_uids = list(llama_results.keys())
    random.shuffle(video_uids)
    
    num_train = int(len(video_uids) * split_ratios[0])
    num_val = int(len(video_uids) * split_ratios[1])
    
    train_set = video_uids[:num_train]
    val_set = video_uids[num_train:num_train + num_val]
    test_set = video_uids[num_train + num_val:]
    
    splits = {"train": train_set, "val": val_set, "test": test_set}
    
    formatted_data = {"version": "1.0", "date": "2024-01-01", "description": "Pretraining data generated by LLaMA", "videos": []}

    for split, video_list in splits.items():
        for video_uid in video_list:
            if video_uid not in llama_results:
                continue
            
            video_entry = {"video_uid": video_uid, "clips": [], "split": split}
            
            for narration_entry in llama_results[video_uid]:
                query_start_sec = narration_entry["query_start_sec"]
                query_end_sec = narration_entry["query_end_sec"]
                clip_uid = narration_entry["clip_uid"]
                video_start_sec = narration_entry["video_start_sec"]
                video_end_sec = narration_entry["video_end_sec"]
                video_start_frame = narration_entry["video_start_frame"]
                video_end_frame = narration_entry["video_end_frame"]
                clip_start_frame = narration_entry["clip_start_frame"]
                clip_end_frame = narration_entry["clip_end_frame"]
                annotation_uid = f"{video_uid}_{str(uuid.uuid4())}"

                video_entry["clips"].append({
                    "clip_uid": clip_uid,
                    "video_start_sec": video_start_sec,
                    "video_end_sec": video_end_sec,
                    "video_start_frame": video_start_frame,
                    "video_end_frame": video_end_frame,
                    "clip_start_sec": round(video_start_sec, 2),
                    "clip_end_sec": round(video_end_sec, 2),
                    "clip_start_frame": video_start_frame,
                    "clip_end_frame": video_end_frame,
                    "source_clip_uid": None,
                    "annotations": [
                        {
                            "language_queries": [
                                {
                                    "clip_start_sec": round(query_start_sec, 3),
                                    "clip_end_sec": round(query_end_sec, 3),
                                    "video_start_sec": query_start_sec,
                                    "video_end_sec": query_end_sec,
                                    "video_start_frame": clip_start_frame,
                                    "video_end_frame": clip_end_frame,
                                    "template": "Llama query",
                                    "query": query,
                                    "slot_x": None,
                                    "verb_x": "[verb_not_applicable]",
                                    "slot_y": None,
                                    "verb_y": "[verb_not_applicable]"
                                }
                                for query in narration_entry["questions"]
                            ],
                            # generate unique annotation_uid
                            "annotation_uid": annotation_uid
                        }
                    ]
                })
            
            formatted_data["videos"].append(video_entry)
    
    # Save formatted data to JSON files
    os.makedirs(output_dir, exist_ok=True)
    for split in splits:
        split_data = {
            "version": "1.0",
            "date": "2025-01-07",
            "description": f"{split.capitalize()} data for VSLNet",
            "videos": [v for v in formatted_data["videos"] if v["split"] == split]
        }
        output_path = os.path.join(output_dir, f"llama_{split}.json")
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(split_data, f, indent=4)
    
    print(f"Formatted data saved to {output_dir}")


def main(args):
    with open(args.llama_results_path, "r") as file:
        llama_results = json.load(file)

    format_llama_results_for_vslnet(llama_results, args.output_dir)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Format the results for the VSLNet.")
    parser.add_argument("--llama_results_path", help="Path to LLaMA-generated results")
    parser.add_argument("--output_dir", help="Output directory for formatted JSON files")

    args = parser.parse_args()
    main(args)
